#!/usr/bin/env python3
"""
VITS testing script with configurable parameters
Loads model directly to allow parameter tuning
"""

import torch
import scipy.io.wavfile as wav
import os
import numpy as np
from pathlib import Path
from transformers import VitsModel, AutoTokenizer
import random

def test_vits():
    """Test VITS model with configurable parameters"""
    
    # ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh Ä‘Ã£ train
    model_dir = r"D:\Workspace\NLP\TEXT-TO-SPEECH\finetune-hf-vits\runs\mms_vie_ft_single_spk"
    
    # Kiá»ƒm tra mÃ´ hÃ¬nh cÃ³ tá»“n táº¡i khÃ´ng
    if not os.path.exists(model_dir):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh á»Ÿ: {model_dir}")
        return
    
    print(f"âœ… TÃ¬m tháº¥y mÃ´ hÃ¬nh á»Ÿ: {model_dir}")
    
    try:
        # Load model vÃ  tokenizer trá»±c tiáº¿p
        print("ğŸ”„ Äang load model vÃ  tokenizer...")
        model = VitsModel.from_pretrained(model_dir)
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        
        # Chuyá»ƒn model lÃªn GPU náº¿u cÃ³
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = model.to(device)
        model.eval()
        
        # Thiáº¿t láº­p seed Ä‘á»ƒ tÃ¡i thiáº¿t láº­p káº¿t quáº£
        seed = 42
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed) if torch.cuda.is_available() else None
        torch.cuda.manual_seed_all(seed) if torch.cuda.is_available() else None
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        np.random.seed(seed)
        
        print(f"ğŸ”¢ Seed Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p: {seed}")
        print(f"   ğŸ² PyTorch seed: {seed}")
        print(f"   ğŸ² NumPy seed: {seed}")
        print(f"   ğŸ”’ Deterministic mode: Báº­t")
        
        print("âœ… ÄÃ£ load model thÃ nh cÃ´ng!")
        print(f"ğŸ“Š Model: {model_dir}")
        print(f"ğŸ”§ Device: {device}")
        print(f"ğŸ“ Vocab size: {model.config.vocab_size}")
        
        # Hiá»ƒn thá»‹ config hiá»‡n táº¡i
        print(f"\nğŸ“‹ Config hiá»‡n táº¡i:")
        print(f"   ğŸµ Noise scale: {model.config.noise_scale}")
        print(f"   ğŸµ Noise scale duration: {model.config.noise_scale_duration}")
        print(f"   ğŸµ Speaking rate: {model.config.speaking_rate}")
        print(f"   ğŸµ Sampling rate: {model.config.sampling_rate}")
        
        # Cáº­p nháº­t config tÃ¹y chá»‰nh
        print(f"\nğŸ”§ Cáº­p nháº­t config...")
        # model.config.noise_scale = 0.5          # Giáº£m noise (á»•n Ä‘á»‹nh hÆ¡n)
        # model.config.noise_scale_duration = 1.2 # Giáº£m variation trong duration
        # model.config.speaking_rate = 0.7       # Cháº­m hÆ¡n má»™t chÃºt
        model.config.noise_scale = 0.5          # Giáº£m noise (á»•n Ä‘á»‹nh hÆ¡n)
        model.config.noise_scale_duration = 0.5 # Giáº£m variation trong duration
        model.config.speaking_rate = 0.9       # Cháº­m hÆ¡n má»™t chÃºt
        
        print(f"   ğŸµ Noise scale: {model.config.noise_scale}")
        print(f"   ğŸµ Noise scale duration: {model.config.noise_scale_duration}")
        print(f"   ğŸµ Speaking rate: {model.config.speaking_rate}")
        
        # Táº¡o thÆ° má»¥c output
        output_dir = Path(r"D:\Workspace\NLP\TEXT-TO-SPEECH\generated_audio")
        output_dir.mkdir(exist_ok=True)
        
        # Cáº¥u hÃ¬nh padding
        padding_start = "  "  # KÃ½ tá»± padding á»Ÿ Ä‘áº§u
        padding_end = " . "    # KÃ½ tá»± padding á»Ÿ cuá»‘i
        
        # Hiá»ƒn thá»‹ cáº¥u hÃ¬nh padding
        print(f"\nğŸ”§ Cáº¥u hÃ¬nh padding:")
        print(f"   ğŸ“ Padding start: '{padding_start}'")
        print(f"   ğŸ“ Padding end: '{padding_end}'")
        
        # Danh sÃ¡ch cÃ¢u test
        test_texts = [
            " Váº­y lÃ  khÃ´ng Ä‘Æ°á»£c Ä‘Ã¢u nhÃ©  "
        ]
        
        print(f"\nğŸ¯ Sáº½ test {len(test_texts)} cÃ¢u vá»›i cáº¥u hÃ¬nh tÃ¹y chá»‰nh")
        
        # Test tá»«ng cÃ¢u
        for text_idx, text in enumerate(test_texts, 1):
            print(f"\nğŸµ Äang táº¡o Ã¢m thanh cho cÃ¢u {text_idx}: {text[:50]}...")
            
            try:
                # ThÃªm kÃ½ tá»± im láº·ng/ngáº¯t cÃ¢u Ä‘á»ƒ trÃ¡nh máº¥t chá»¯ á»Ÿ Ä‘áº§u/cuá»‘i
                padded_text = padding_start + text + padding_end
                print(f"   ğŸ“ Text gá»‘c: {text}")
                print(f"   ğŸ“ Text Ä‘Ã£ pad: {padded_text}")
                
                # Tokenize text Ä‘Ã£ pad
                inputs = tokenizer(padded_text, return_tensors="pt").to(device)
                
                # Generate speech
                with torch.no_grad():
                    output = model(**inputs)
                
                # Láº¥y waveform
                waveform = output.waveform.squeeze().cpu().numpy()
                sampling_rate = model.config.sampling_rate
                
                # LÆ°u file
                output_file = output_dir / f"test_custom_{text_idx}.wav"
                wav.write(str(output_file), sampling_rate, waveform)
                
                # ThÃ´ng tin vá» audio
                audio_duration = len(waveform) / sampling_rate
                print(f"âœ… ÄÃ£ lÆ°u: {output_file.name}")
                print(f"   ğŸ“Š Sampling rate: {sampling_rate} Hz")
                print(f"   â±ï¸  Duration: {audio_duration:.2f} seconds")
                print(f"   ğŸ“ Audio length: {len(waveform)} samples")
                
            except Exception as e:
                print(f"âŒ Lá»—i khi táº¡o audio cho cÃ¢u {text_idx}: {e}")
                continue
        
        print(f"\nğŸ‰ HoÃ n thÃ nh! ÄÃ£ táº¡o {len(test_texts)} file Ã¢m thanh trong: {output_dir}")
        print(f"\nğŸ’¡ CÃ¡c file Ä‘Æ°á»£c táº¡o:")
        for text_idx in range(1, len(test_texts) + 1):
            filename = f"test_custom_{text_idx}.wav"
            print(f"   ğŸ“ {filename}")
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_vits()
